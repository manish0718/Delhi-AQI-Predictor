{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004114</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>-0.044459</td>\n",
       "      <td>-0.042408</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.318835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.997338</td>\n",
       "      <td>1.021776</td>\n",
       "      <td>1.011768</td>\n",
       "      <td>1.017189</td>\n",
       "      <td>0.978654</td>\n",
       "      <td>110.741562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.380125</td>\n",
       "      <td>-3.314844</td>\n",
       "      <td>-3.153118</td>\n",
       "      <td>-3.250169</td>\n",
       "      <td>-2.851707</td>\n",
       "      <td>-379.829794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.647165</td>\n",
       "      <td>-0.705030</td>\n",
       "      <td>-0.706385</td>\n",
       "      <td>-0.709504</td>\n",
       "      <td>-0.615880</td>\n",
       "      <td>-71.897040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000360</td>\n",
       "      <td>-0.043769</td>\n",
       "      <td>-0.041272</td>\n",
       "      <td>-0.029756</td>\n",
       "      <td>-0.013527</td>\n",
       "      <td>-0.610665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.682118</td>\n",
       "      <td>0.645442</td>\n",
       "      <td>0.639130</td>\n",
       "      <td>0.646290</td>\n",
       "      <td>0.650089</td>\n",
       "      <td>71.226603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.287205</td>\n",
       "      <td>3.438895</td>\n",
       "      <td>3.216176</td>\n",
       "      <td>2.985410</td>\n",
       "      <td>3.321770</td>\n",
       "      <td>337.643014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_1    feature_2    feature_3    feature_4    feature_5  \\\n",
       "count  1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "mean      0.004114    -0.027604    -0.044459    -0.042408     0.012005   \n",
       "std       0.997338     1.021776     1.011768     1.017189     0.978654   \n",
       "min      -3.380125    -3.314844    -3.153118    -3.250169    -2.851707   \n",
       "25%      -0.647165    -0.705030    -0.706385    -0.709504    -0.615880   \n",
       "50%      -0.000360    -0.043769    -0.041272    -0.029756    -0.013527   \n",
       "75%       0.682118     0.645442     0.639130     0.646290     0.650089   \n",
       "max       3.287205     3.438895     3.216176     2.985410     3.321770   \n",
       "\n",
       "            target  \n",
       "count  1600.000000  \n",
       "mean      0.318835  \n",
       "std     110.741562  \n",
       "min    -379.829794  \n",
       "25%     -71.897040  \n",
       "50%      -0.610665  \n",
       "75%      71.226603  \n",
       "max     337.643014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.021804</td>\n",
       "      <td>-0.012806</td>\n",
       "      <td>-0.010988</td>\n",
       "      <td>-0.034864</td>\n",
       "      <td>0.031016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.979163</td>\n",
       "      <td>1.021580</td>\n",
       "      <td>1.041857</td>\n",
       "      <td>1.034507</td>\n",
       "      <td>0.937469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.564288</td>\n",
       "      <td>-2.992849</td>\n",
       "      <td>-2.767818</td>\n",
       "      <td>-3.041550</td>\n",
       "      <td>-2.493446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.784581</td>\n",
       "      <td>-0.640843</td>\n",
       "      <td>-0.780267</td>\n",
       "      <td>-0.730596</td>\n",
       "      <td>-0.589199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.004759</td>\n",
       "      <td>-0.077186</td>\n",
       "      <td>-0.109300</td>\n",
       "      <td>-0.040752</td>\n",
       "      <td>0.047327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.681777</td>\n",
       "      <td>0.738286</td>\n",
       "      <td>0.754063</td>\n",
       "      <td>0.656363</td>\n",
       "      <td>0.586405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.244870</td>\n",
       "      <td>2.591723</td>\n",
       "      <td>2.909357</td>\n",
       "      <td>2.662180</td>\n",
       "      <td>2.870382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature_1   feature_2   feature_3   feature_4   feature_5\n",
       "count  400.000000  400.000000  400.000000  400.000000  400.000000\n",
       "mean    -0.021804   -0.012806   -0.010988   -0.034864    0.031016\n",
       "std      0.979163    1.021580    1.041857    1.034507    0.937469\n",
       "min     -2.564288   -2.992849   -2.767818   -3.041550   -2.493446\n",
       "25%     -0.784581   -0.640843   -0.780267   -0.730596   -0.589199\n",
       "50%     -0.004759   -0.077186   -0.109300   -0.040752    0.047327\n",
       "75%      0.681777    0.738286    0.754063    0.656363    0.586405\n",
       "max      3.244870    2.591723    2.909357    2.662180    2.870382"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e51606c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(data.corr()) #relation between different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating two arrays one dependent and one independent\n",
    "x = data.drop('target',axis=1)\n",
    "y = data['target']\n",
    "x_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 5)\n",
      "(1600,)\n",
      "(400, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs0\n",
      "Training cost :6128.065207016449\n",
      "Training MAE :87.90988758822989\n",
      "Weights are :   [2.88141079 9.46938203 0.27528012 4.38864658 0.16339952]\n",
      "Bias is :  0.03188353844158139\n",
      "\n",
      "Epochs1\n",
      "Training cost :5013.016842071536\n",
      "Training MAE :79.44532559414489\n",
      "Weights are :   [ 5.4811785  17.98853606  0.57859548  8.35409442  0.31487708]\n",
      "Bias is :  0.06057872303900473\n",
      "\n",
      "Epochs2\n",
      "Training cost :4108.52762640881\n",
      "Training MAE :71.8633132592893\n",
      "Weights are :   [ 7.82694663 25.65309881  0.90161002 11.93715743  0.45556687]\n",
      "Bias is :  0.08640438917668568\n",
      "\n",
      "Epochs3\n",
      "Training cost :3374.7333135069775\n",
      "Training MAE :65.07963222978368\n",
      "Weights are :   [ 9.94363349 32.5490533   1.2373764  15.17471358  0.58645728]\n",
      "Bias is :  0.10964748870059857\n",
      "\n",
      "Epochs4\n",
      "Training cost :2779.3365935446445\n",
      "Training MAE :59.00986050025896\n",
      "Weights are :   [11.85370213 38.75370615  1.58014097 18.10008436  0.70841256]\n",
      "Bias is :  0.13056627827212025\n",
      "\n",
      "Epochs5\n",
      "Training cost :2296.167033736997\n",
      "Training MAE :53.5913373916589\n",
      "Weights are :   [13.57740335 44.33656559  1.925174   20.74337771  0.82219121]\n",
      "Bias is :  0.14939318888648961\n",
      "\n",
      "Epochs6\n",
      "Training cost :1904.0157828958577\n",
      "Training MAE :48.7617766334774\n",
      "Weights are :   [15.1329946  49.36013043  2.26862207 23.13179785  0.92846157]\n",
      "Bias is :  0.16633740843942205\n",
      "\n",
      "Epochs7\n",
      "Training cost :1585.6924804475693\n",
      "Training MAE :44.47384780893293\n",
      "Weights are :   [16.53693704 53.88059898  2.60737969 25.28992528  1.02781504]\n",
      "Bias is :  0.18158720603706133\n",
      "\n",
      "Epochs8\n",
      "Training cost :1327.2618899729187\n",
      "Training MAE :40.667546550308025\n",
      "Weights are :   [17.80407311 57.94850602  2.93897807 27.23996981  1.12077728]\n",
      "Bias is :  0.1953120238749367\n",
      "\n",
      "Epochs9\n",
      "Training cost :1117.4259191740748\n",
      "Training MAE :37.30273299955734\n",
      "Weights are :   [18.94778643 61.60929522  3.26148853 29.00199915  1.20781773]\n",
      "Bias is :  0.20766435992902466\n",
      "\n",
      "Epochs10\n",
      "Training cost :947.0232655663248\n",
      "Training MAE :34.3496701235698\n",
      "Weights are :   [19.98014579 64.90383355  3.57343906 30.59414551  1.28935757]\n",
      "Bias is :  0.21878146237770357\n",
      "\n",
      "Epochs11\n",
      "Training cost :808.6242415004881\n",
      "Training MAE :31.758571357548234\n",
      "Weights are :   [20.91203492 67.86887355  3.87374208 32.03279224  1.36577653]\n",
      "Bias is :  0.2287868545815146\n",
      "\n",
      "Epochs12\n",
      "Training cost :696.2026265116409\n",
      "Training MAE :29.516728277668484\n",
      "Weights are :   [21.75326936 70.53746876  4.16163225 33.3327425   1.43741858]\n",
      "Bias is :  0.23779170756494453\n",
      "\n",
      "Epochs13\n",
      "Training cost :604.869865696847\n",
      "Training MAE :27.56371113196785\n",
      "Weights are :   [22.51270177 72.93934712  4.43661276 34.50737168  1.50459679]\n",
      "Bias is :  0.2458960752500317\n",
      "\n",
      "Epochs14\n",
      "Training cost :530.6597382339138\n",
      "Training MAE :25.878529628840035\n",
      "Weights are :   [23.1983168  75.10124652  4.69840926 35.5687651   1.56759736]\n",
      "Bias is :  0.25319000616661\n",
      "\n",
      "Epochs15\n",
      "Training cost :470.3538881177537\n",
      "Training MAE :24.422207148758567\n",
      "Weights are :   [23.81731653 77.04721646  4.94693031 36.52784241  1.62668307]\n",
      "Bias is :  0.2597545439915306\n",
      "\n",
      "Epochs16\n",
      "Training cost :421.3404429321311\n",
      "Training MAE :23.147100302791348\n",
      "Weights are :   [24.37619755 78.79888911  5.18223352 37.39447008  1.6820962 ]\n",
      "Bias is :  0.26566262803395885\n",
      "\n",
      "Epochs17\n",
      "Training cost :381.4994293393234\n",
      "Training MAE :22.051822173529594\n",
      "Weights are :   [24.88082035 80.37572303  5.40449665 38.1775629   1.73406092]\n",
      "Bias is :  0.2709799036721443\n",
      "\n",
      "Epochs18\n",
      "Training cost :349.10989326718874\n",
      "Training MAE :21.131307591696523\n",
      "Weights are :   [25.33647185 81.7952222   5.61399305 38.88517588  1.78278538]\n",
      "Bias is :  0.2757654517465113\n",
      "\n",
      "Epochs19\n",
      "Training cost :322.7746028666723\n",
      "Training MAE :20.339821646376347\n",
      "Weights are :   [25.74792178 83.07313297  5.81107074 39.52458708  1.82846349]\n",
      "Bias is :  0.2800724450134419\n",
      "\n",
      "Epochs20\n",
      "Training cost :301.3589971184099\n",
      "Training MAE :19.661895422408985\n",
      "Weights are :   [26.1194735  84.22362101  5.99613477 40.10237264  1.87127632]\n",
      "Bias is :  0.28394873895367906\n",
      "\n",
      "Epochs21\n",
      "Training cost :283.9416779648998\n",
      "Training MAE :19.089748258573582\n",
      "Weights are :   [26.45500978 85.25943051  6.16963242 40.62447441  1.91139342]\n",
      "Bias is :  0.2874374034998926\n",
      "\n",
      "Epochs22\n",
      "Training cost :269.77425770362055\n",
      "Training MAE :18.621333986807993\n",
      "Weights are :   [26.75803406 86.19202721  6.33204067 41.09626119  1.94897388]\n",
      "Bias is :  0.29057720159148476\n",
      "\n",
      "Epochs23\n",
      "Training cost :258.2487892651389\n",
      "Training MAE :18.235391506039328\n",
      "Weights are :   [27.03170771 87.03172704  6.48385586 41.52258399  1.9841672 ]\n",
      "Bias is :  0.2934030198739179\n",
      "\n",
      "Epochs24\n",
      "Training cost :248.8713436449135\n",
      "Training MAE :17.916096117631554\n",
      "Weights are :   [27.2788835  87.78781178  6.62558511 41.90782595  2.01711413]\n",
      "Bias is :  0.2959462563281075\n",
      "\n",
      "Epochs25\n",
      "Training cost :241.24057129597074\n",
      "Training MAE :17.65021929821502\n",
      "Weights are :   [27.5021359  88.46863301  6.75773918 42.25594752  2.04794732]\n",
      "Bias is :  0.2982351691368783\n",
      "\n",
      "Epochs26\n",
      "Training cost :235.03030496060987\n",
      "Training MAE :17.434295955077097\n",
      "Weights are :   [27.70378832 89.08170564  6.88082678 42.5705272   2.07679188]\n",
      "Bias is :  0.30029519066477195\n",
      "\n",
      "Epochs27\n",
      "Training cost :229.97544011906237\n",
      "Training MAE :17.256731815047424\n",
      "Weights are :   [27.88593767 89.63379196  6.99534984 42.85479837  2.10376596]\n",
      "Bias is :  0.3021492100398765\n",
      "\n",
      "Epochs28\n",
      "Training cost :225.8604739648168\n",
      "Training MAE :17.108324486121315\n",
      "Weights are :   [28.05047658 90.13097724  7.10179991 43.11168262  2.12898116]\n",
      "Bias is :  0.3038178274774703\n",
      "\n",
      "Epochs29\n",
      "Training cost :222.51020105342513\n",
      "Training MAE :16.983752095460833\n",
      "Weights are :   [28.19911331 90.57873772  7.20065518 43.34381979  2.15254294]\n",
      "Bias is :  0.30531958317130464\n",
      "\n",
      "Epochs30\n",
      "Training cost :219.78215875054505\n",
      "Training MAE :16.881047949537336\n",
      "Weights are :   [28.33338985 90.98200176  7.2923783  43.55359518  2.17455095]\n",
      "Bias is :  0.3066711632957557\n",
      "\n",
      "Epochs31\n",
      "Training cost :217.56049256240607\n",
      "Training MAE :16.79659417220111\n",
      "Weights are :   [28.45469811 91.34520478  7.37741477 43.74316407  2.19509943]\n",
      "Bias is :  0.3078875854077615\n",
      "\n",
      "Epochs32\n",
      "Training cost :215.75097379600535\n",
      "Training MAE :16.729780893734283\n",
      "Weights are :   [28.56429462 91.67233874  7.45619173 43.91447391  2.21427742]\n",
      "Bias is :  0.30898236530856693\n",
      "\n",
      "Epochs33\n",
      "Training cost :214.2769525415334\n",
      "Training MAE :16.676304188960565\n",
      "Weights are :   [28.66331372 91.96699662  7.52911726 44.06928438  2.23216911]\n",
      "Bias is :  0.30996766721929186\n",
      "\n",
      "Epochs34\n",
      "Training cost :213.07606994139277\n",
      "Training MAE :16.632253356497294\n",
      "Weights are :   [28.75277953 92.23241237  7.59657993 44.20918552  2.24885401]\n",
      "Bias is :  0.31085443893894404\n",
      "\n",
      "Epochs35\n",
      "Training cost :212.09758692655146\n",
      "Training MAE :16.595218059896187\n",
      "Weights are :   [28.83361663 92.47149696  7.65894866 44.33561404  2.26440726]\n",
      "Bias is :  0.311652533486631\n",
      "\n",
      "Epochs36\n",
      "Training cost :211.30021353364555\n",
      "Training MAE :16.564605914759813\n",
      "Weights are :   [28.90665984 92.68687066  7.71657278 44.44986814  2.2788998 ]\n",
      "Bias is :  0.3123708185795493\n",
      "\n",
      "Epochs37\n",
      "Training cost :210.65034475697215\n",
      "Training MAE :16.538798616781634\n",
      "Weights are :   [28.97266294 92.88089224  7.76978232 44.55312088  2.29239858]\n",
      "Bias is :  0.3130172751631758\n",
      "\n",
      "Epochs38\n",
      "Training cost :210.12062660345418\n",
      "Training MAE :16.517238433478465\n",
      "Weights are :   [29.03230655 93.05568506  7.81888837 44.64643221  2.30496678]\n",
      "Bias is :  0.31359908608844\n",
      "\n",
      "Epochs39\n",
      "Training cost :209.68879038756273\n",
      "Training MAE :16.50026610113892\n",
      "Weights are :   [29.08620528 93.2131607   7.86418361 44.73075993  2.31666397]\n",
      "Bias is :  0.31412271592117763\n",
      "\n",
      "Epochs40\n",
      "Training cost :209.33670496032508\n",
      "Training MAE :16.486006893796713\n",
      "Weights are :   [29.13491414 93.35504012  7.90594289 44.8069695   2.32754629]\n",
      "Bias is :  0.31459398277064166\n",
      "\n",
      "Epochs41\n",
      "Training cost :209.0496060250178\n",
      "Training MAE :16.475148368144183\n",
      "Weights are :   [29.17893434 93.48287273  7.94442394 44.87584294  2.33766666]\n",
      "Bias is :  0.3150181229351589\n",
      "\n",
      "Epochs42\n",
      "Training cost :208.81546936769564\n",
      "Training MAE :16.46718421148408\n",
      "Weights are :   [29.21871854 93.59805355  7.979868   44.93808693  2.34707485]\n",
      "Bias is :  0.3153998490832247\n",
      "\n",
      "Epochs43\n",
      "Training cost :208.62450106027842\n",
      "Training MAE :16.461391764218842\n",
      "Weights are :   [29.25467556 93.70183861  8.01250059 44.99434002  2.35581773]\n",
      "Bias is :  0.31574340261648365\n",
      "\n",
      "Epochs44\n",
      "Training cost :208.46872275060946\n",
      "Training MAE :16.456818146570917\n",
      "Weights are :   [29.28717463 93.79535888  8.04253229 45.04517921  2.36393936]\n",
      "Bias is :  0.31605260079641684\n",
      "\n",
      "Epochs45\n",
      "Training cost :208.34163425910194\n",
      "Training MAE :16.453270721412064\n",
      "Weights are :   [29.31654925 93.87963275  8.07015944 45.09112592  2.37148117]\n",
      "Bias is :  0.316330879158357\n",
      "\n",
      "Epochs46\n",
      "Training cost :208.2379390347935\n",
      "Training MAE :16.45033733469517\n",
      "Weights are :   [29.34310065 93.95557724  8.09556493 45.13265129  2.37848205]\n",
      "Bias is :  0.31658132968410285\n",
      "\n",
      "Epochs47\n",
      "Training cost :208.15332073038365\n",
      "Training MAE :16.447939202925742\n",
      "Weights are :   [29.36710095 94.02401816  8.11891893 45.17018108  2.38497853]\n",
      "Bias is :  0.31680673515727414\n",
      "\n",
      "Epochs48\n",
      "Training cost :208.0842613541713\n",
      "Training MAE :16.44627066573466\n",
      "Weights are :   [29.38879592 94.08569918  8.14037963 45.20410004  2.39100487]\n",
      "Bias is :  0.3170096000831282\n",
      "\n",
      "Epochs49\n",
      "Training cost :208.02789324247374\n",
      "Training MAE :16.4451268555313\n",
      "Weights are :   [29.40840762 94.14129007  8.16009392 45.23475581  2.3965932 ]\n",
      "Bias is :  0.31719217851639686\n",
      "\n",
      "Epochs50\n",
      "Training cost :207.98187854676777\n",
      "Training MAE :16.444117580493526\n",
      "Weights are :   [29.42613665 94.191394    8.17819811 45.26246256  2.40177364]\n",
      "Bias is :  0.3173564991063389\n",
      "\n",
      "Epochs51\n",
      "Training cost :207.94431110845002\n",
      "Training MAE :16.443211642418255\n",
      "Weights are :   [29.44216421 94.23655423  8.1948186  45.28750421  2.40657439]\n",
      "Bias is :  0.3175043876372863\n",
      "\n",
      "Epochs52\n",
      "Training cost :207.91363655190224\n",
      "Training MAE :16.442409894200974\n",
      "Weights are :   [29.45665404 94.27726006  8.21007246 45.31013729  2.41102185]\n",
      "Bias is :  0.3176374873151392\n",
      "\n",
      "Epochs53\n",
      "Training cost :207.88858720496225\n",
      "Training MAE :16.441976721973134\n",
      "Weights are :   [29.46975406 94.31395224  8.22406807 45.33059365  2.41514073]\n",
      "Bias is :  0.31775727702520656\n",
      "\n",
      "Epochs54\n",
      "Training cost :207.8681290886155\n",
      "Training MAE :16.44163665473723\n",
      "Weights are :   [29.48159792 94.34702774  8.23690572 45.34908279  2.41895411]\n",
      "Bias is :  0.3178650877642674\n",
      "\n",
      "Epochs55\n",
      "Training cost :207.85141873208283\n",
      "Training MAE :16.441332848648994\n",
      "Weights are :   [29.49230639 94.37684416  8.24867809 45.36579405  2.42248359]\n",
      "Bias is :  0.31796211742942254\n",
      "\n",
      "Epochs56\n",
      "Training cost :207.83776798767605\n",
      "Training MAE :16.44110859166536\n",
      "Weights are :   [29.50198859 94.40372363  8.25947086 45.38089851  2.42574933]\n",
      "Bias is :  0.3180494441280618\n",
      "\n",
      "Epochs57\n",
      "Training cost :207.8266153598549\n",
      "Training MAE :16.440944390600208\n",
      "Weights are :   [29.51074313 94.42795635  8.26936311 45.39455079  2.42877016]\n",
      "Bias is :  0.31812803815683705\n",
      "\n",
      "Epochs58\n",
      "Training cost :207.81750263947342\n",
      "Training MAE :16.440826283454747\n",
      "Weights are :   [29.5186591  94.44980375  8.27842784 45.40689063  2.43156364]\n",
      "Bias is :  0.318198772782735\n",
      "\n",
      "Epochs59\n",
      "Training cost :207.8100558591515\n",
      "Training MAE :16.440721598801513\n",
      "Weights are :   [29.52581703 94.46950136  8.28673239 45.41804429  2.43414615]\n",
      "Bias is :  0.31826243394604325\n",
      "\n",
      "Epochs60\n",
      "Training cost :207.80396976869204\n",
      "Training MAE :16.44062883007505\n",
      "Weights are :   [29.53228969 94.48726138  8.29433884 45.42812589  2.43653298]\n",
      "Bias is :  0.31831972899302036\n",
      "\n",
      "Epochs61\n",
      "Training cost :207.79899517834144\n",
      "Training MAE :16.44054663821107\n",
      "Weights are :   [29.53814284 94.50327499  8.30130438 45.43723857  2.43873835]\n",
      "Bias is :  0.31837129453529983\n",
      "\n",
      "Epochs62\n",
      "Training cost :207.79492863882996\n",
      "Training MAE :16.440473833160294\n",
      "Weights are :   [29.54343592 94.51771447  8.30768172 45.44547551  2.44077552]\n",
      "Bias is :  0.3184177035233516\n",
      "\n",
      "Epochs63\n",
      "Training cost :207.79160402571245\n",
      "Training MAE :16.440431346478665\n",
      "Weights are :   [29.54822265 94.53073503  8.31351937 45.45292095  2.44265682]\n",
      "Bias is :  0.318459471612598\n",
      "\n",
      "Epochs64\n",
      "Training cost :207.78888567576615\n",
      "Training MAE :16.44044359024287\n",
      "Weights are :   [29.55255158 94.54247654  8.31886198 45.45965102  2.44439375]\n",
      "Bias is :  0.31849706289292007\n",
      "\n",
      "Epochs65\n",
      "Training cost :207.7866627885179\n",
      "Training MAE :16.440459830729377\n",
      "Weights are :   [29.5564666  94.55306504  8.32375063 45.46573449  2.44599697]\n",
      "Bias is :  0.3185308950452095\n",
      "\n",
      "Epochs66\n",
      "Training cost :207.78484485914615\n",
      "Training MAE :16.440490912323593\n",
      "Weights are :   [29.56000737 94.56261411  8.32822308 45.47123356  2.44747642]\n",
      "Bias is :  0.31856134398227015\n",
      "\n",
      "Epochs67\n",
      "Training cost :207.78335795229805\n",
      "Training MAE :16.440534997963695\n",
      "Weights are :   [29.56320976 94.5712261   8.33231407 45.47620441  2.44884132]\n",
      "Bias is :  0.31858874802562465\n",
      "\n",
      "Epochs68\n",
      "Training cost :207.78214166161933\n",
      "Training MAE :16.440577156095273\n",
      "Weights are :   [29.56610617 94.57899326  8.3360555  45.48069782  2.45010025]\n",
      "Bias is :  0.3186134116646438\n",
      "\n",
      "Epochs69\n",
      "Training cost :207.78114662850763\n",
      "Training MAE :16.44061596253611\n",
      "Weights are :   [29.5687259  94.58599872  8.33947668 45.48475969  2.45126116]\n",
      "Bias is :  0.318635608939761\n",
      "\n",
      "Epochs70\n",
      "Training cost :207.7803325169899\n",
      "Training MAE :16.44065166739559\n",
      "Weights are :   [29.57109544 94.59231742  8.34260453 45.48843151  2.45233144]\n",
      "Bias is :  0.3186555864873667\n",
      "\n",
      "Epochs71\n",
      "Training cost :207.7796663606766\n",
      "Training MAE :16.4406930251379\n",
      "Weights are :   [29.57323874 94.59801689  8.34546376 45.49175075  2.45331796]\n",
      "Bias is :  0.31867356628021193\n",
      "\n",
      "Epochs72\n",
      "Training cost :207.77912121327097\n",
      "Training MAE :16.440732711004586\n",
      "Weights are :   [29.57517745 94.603158    8.34807707 45.49475132  2.45422706]\n",
      "Bias is :  0.3186897480937725\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs73\n",
      "Training cost :207.77867504675828\n",
      "Training MAE :16.44076910556971\n",
      "Weights are :   [29.57693113 94.60779563  8.35046525 45.49746382  2.45506464]\n",
      "Bias is :  0.31870431172597696\n",
      "\n",
      "Epochs74\n",
      "Training cost :207.7783098517127\n",
      "Training MAE :16.440802471729132\n",
      "Weights are :   [29.57851749 94.61197923  8.3526474  45.49991595  2.45583617]\n",
      "Bias is :  0.31871741899496053\n",
      "\n",
      "Epochs75\n",
      "Training cost :207.77801090255664\n",
      "Training MAE :16.44083305260817\n",
      "Weights are :   [29.57995252 94.6157534   8.35464102 45.50213271  2.45654671]\n",
      "Bias is :  0.318729215537046\n",
      "\n",
      "Epochs76\n",
      "Training cost :207.77776615746197\n",
      "Training MAE :16.440861072892787\n",
      "Weights are :   [29.58125068 94.61915833  8.35646217 45.50413672  2.45720095]\n",
      "Bias is :  0.3187398324249229\n",
      "\n",
      "Epochs77\n",
      "Training cost :207.77756576816114\n",
      "Training MAE :16.44088674009203\n",
      "Weights are :   [29.58242506 94.62223026  8.35812555 45.50594842  2.45780323]\n",
      "Bias is :  0.31874938762401234\n",
      "\n",
      "Epochs78\n",
      "Training cost :207.77740167949258\n",
      "Training MAE :16.4409102457322\n",
      "Weights are :   [29.58348749 94.62500185  8.35964464 45.50758629  2.45835756]\n",
      "Bias is :  0.31875798730319255\n",
      "\n",
      "Epochs79\n",
      "Training cost :207.77726730221562\n",
      "Training MAE :16.440931766483786\n",
      "Weights are :   [29.58444865 94.62750256  8.3610318  45.509067    2.45886767]\n",
      "Bias is :  0.3187657270144549\n",
      "\n",
      "Epochs80\n",
      "Training cost :207.77715724565925\n",
      "Training MAE :16.440951465222533\n",
      "Weights are :   [29.58531823 94.62975895  8.36229833 45.51040567  2.459337  ]\n",
      "Bias is :  0.3187726927545908\n",
      "\n",
      "Epochs81\n",
      "Training cost :207.77706709923703\n",
      "Training MAE :16.440969492026735\n",
      "Weights are :   [29.58610495 94.63179497  8.36345459 45.51161592  2.45976873]\n",
      "Bias is :  0.31877896192071353\n",
      "\n",
      "Epochs82\n",
      "Training cost :207.77699325387673\n",
      "Training MAE :16.440985985112658\n",
      "Weights are :   [29.58681674 94.63363219  8.36451007 45.51271009  2.4601658 ]\n",
      "Bias is :  0.31878460417022375\n",
      "\n",
      "Epochs83\n",
      "Training cost :207.77693275605642\n",
      "Training MAE :16.44100107171071\n",
      "Weights are :   [29.58746074 94.6352901   8.36547345 45.51369933  2.46053093]\n",
      "Bias is :  0.3187896821947832\n",
      "\n",
      "Epochs84\n",
      "Training cost :207.7768831884801\n",
      "Training MAE :16.4410148688847\n",
      "Weights are :   [29.58804343 94.63678625  8.36635267 45.5145937   2.46086662]\n",
      "Bias is :  0.318794252416886\n",
      "\n",
      "Epochs85\n",
      "Training cost :207.77684257251914\n",
      "Training MAE :16.44102748429689\n",
      "Weights are :   [29.58857064 94.63813647  8.36715501 45.51540232  2.4611752 ]\n",
      "Bias is :  0.3187983656167791\n",
      "\n",
      "Epochs86\n",
      "Training cost :207.77680928844188\n",
      "Training MAE :16.441039016921465\n",
      "Weights are :   [29.58904768 94.63935503  8.36788711 45.5161334   2.46145881]\n",
      "Bias is :  0.3188020674966827\n",
      "\n",
      "Epochs87\n",
      "Training cost :207.77678201018003\n",
      "Training MAE :16.4410495577091\n",
      "Weights are :   [29.58947932 94.64045483  8.36855507 45.51679441  2.46171943]\n",
      "Bias is :  0.3188053991885963\n",
      "\n",
      "Epochs88\n",
      "Training cost :207.77675965197687\n",
      "Training MAE :16.441059190205266\n",
      "Weights are :   [29.5898699  94.64144746  8.36916443 45.51739205  2.46195888]\n",
      "Bias is :  0.31880839771131847\n",
      "\n",
      "Epochs89\n",
      "Training cost :207.77674132474908\n",
      "Training MAE :16.441067991124925\n",
      "Weights are :   [29.59022332 94.6423434   8.3697203  45.51793241  2.46217886]\n",
      "Bias is :  0.31881109638176836\n",
      "\n",
      "Epochs90\n",
      "Training cost :207.77672630038927\n",
      "Training MAE :16.441076030886105\n",
      "Weights are :   [29.59054313 94.6431521   8.37022733 45.51842098  2.4623809 ]\n",
      "Bias is :  0.3188135251851731\n",
      "\n",
      "Epochs91\n",
      "Training cost :207.77671398256135\n",
      "Training MAE :16.441083374104906\n",
      "Weights are :   [29.59083253 94.64388209  8.37068976 45.51886274  2.46256644]\n",
      "Bias is :  0.3188157111082374\n",
      "\n",
      "Epochs92\n",
      "Training cost :207.7767038828049\n",
      "Training MAE :16.44109008005424\n",
      "Weights are :   [29.59109442 94.64454104  8.37111148 45.51926217  2.46273681]\n",
      "Bias is :  0.318817678438995\n",
      "\n",
      "Epochs93\n",
      "Training cost :207.7766956009825\n",
      "Training MAE :16.441096203088737\n",
      "Weights are :   [29.59133142 94.64513589  8.37149605 45.51962334  2.46289323]\n",
      "Bias is :  0.31881944903667725\n",
      "\n",
      "Epochs94\n",
      "Training cost :207.7766888092775\n",
      "Training MAE :16.441101793037873\n",
      "Weights are :   [29.59154589 94.64567289  8.37184671 45.5199499   2.46303681]\n",
      "Bias is :  0.31882104257459104\n",
      "\n",
      "Epochs95\n",
      "Training cost :207.77668323909734\n",
      "Training MAE :16.441106895569543\n",
      "Weights are :   [29.59173998 94.6461577   8.37216643 45.52024519  2.46316859]\n",
      "Bias is :  0.3188224767587131\n",
      "\n",
      "Epochs96\n",
      "Training cost :207.77667867035308\n",
      "Training MAE :16.441111552525996\n",
      "Weights are :   [29.59191563 94.64659539  8.37245791 45.52051219  2.46328952]\n",
      "Bias is :  0.3188237675244231\n",
      "\n",
      "Epochs97\n",
      "Training cost :207.7766749226837\n",
      "Training MAE :16.441115802234087\n",
      "Weights are :   [29.5920746  94.64699056  8.37272363 45.52075363  2.46340048]\n",
      "Bias is :  0.3188249292135622\n",
      "\n",
      "Epochs98\n",
      "Training cost :207.77667184827126\n",
      "Training MAE :16.44111967979157\n",
      "Weights are :   [29.59221847 94.64734736  8.37296585 45.52097195  2.46350228]\n",
      "Bias is :  0.3188259747337878\n",
      "\n",
      "Epochs99\n",
      "Training cost :207.77666932595753\n",
      "Training MAE :16.44112321733121\n",
      "Weights are :   [29.59234868 94.64766952  8.37318663 45.52116937  2.46359567]\n",
      "Bias is :  0.3188269157019908\n",
      "\n",
      "Epochs100\n",
      "Training cost :207.77666725642715\n",
      "Training MAE :16.441126444264214\n",
      "Weights are :   [29.59246653 94.64796041  8.37338786 45.52134788  2.46368132]\n",
      "Bias is :  0.318827762573373\n",
      "\n",
      "Epochs101\n",
      "Training cost :207.7766655582621\n",
      "Training MAE :16.44112938750452\n",
      "Weights are :   [29.5925732  94.64822308  8.37357125 45.52150931  2.46375987]\n",
      "Bias is :  0.3188285247576173\n",
      "\n",
      "Epochs102\n",
      "Training cost :207.77666416471072\n",
      "Training MAE :16.44113207167538\n",
      "Weights are :   [29.59266974 94.64846028  8.37373838 45.52165529  2.46383189]\n",
      "Bias is :  0.31882921072343723\n",
      "\n",
      "Epochs103\n",
      "Training cost :207.77666302104063\n",
      "Training MAE :16.441134519299464\n",
      "Weights are :   [29.59275711 94.64867448  8.37389067 45.5217873   2.46389793]\n",
      "Bias is :  0.3188298280926752\n",
      "\n",
      "Epochs104\n",
      "Training cost :207.77666208237082\n",
      "Training MAE :16.441136750973797\n",
      "Weights are :   [29.5928362  94.64886792  8.37402944 45.52190668  2.46395847]\n",
      "Bias is :  0.31883038372498923\n",
      "\n",
      "Epochs105\n",
      "Training cost :207.7766613118953\n",
      "Training MAE :16.441138785530608\n",
      "Weights are :   [29.59290779 94.64904261  8.37415588 45.52201463  2.46401396]\n",
      "Bias is :  0.3188308837940721\n",
      "\n",
      "Epochs106\n",
      "Training cost :207.77666067942744\n",
      "Training MAE :16.441140640185207\n",
      "Weights are :   [29.59297259 94.64920039  8.37427108 45.52211226  2.46406482]\n",
      "Bias is :  0.3188313338562462\n",
      "\n",
      "Epochs107\n",
      "Training cost :207.77666016020754\n",
      "Training MAE :16.441142330671873\n",
      "Weights are :   [29.59303124 94.64934289  8.37437602 45.52220055  2.46411143]\n",
      "Bias is :  0.31883173891220284\n",
      "\n",
      "Epochs108\n",
      "Training cost :207.77665973392544\n",
      "Training MAE :16.441143871368634\n",
      "Weights are :   [29.59308433 94.6494716   8.37447163 45.5222804   2.46415413]\n",
      "Bias is :  0.31883210346256413\n",
      "\n",
      "Epochs109\n",
      "Training cost :207.7766593839196\n",
      "Training MAE :16.4411452754119\n",
      "Weights are :   [29.59313239 94.64958785  8.37455872 45.5223526   2.46419326]\n",
      "Bias is :  0.3188324315578891\n",
      "\n",
      "Epochs110\n",
      "Training cost :207.77665909652023\n",
      "Training MAE :16.44114655480161\n",
      "Weights are :   [29.59317589 94.64969286  8.37463805 45.52241791  2.46422911]\n",
      "Bias is :  0.3188327268436815\n",
      "\n",
      "Epochs111\n",
      "Training cost :207.77665886051145\n",
      "Training MAE :16.441147720497778\n",
      "Weights are :   [29.59321527 94.64978771  8.37471031 45.52247697  2.46426194]\n",
      "Bias is :  0.318832992600895\n",
      "\n",
      "Epochs112\n",
      "Training cost :207.77665866669005\n",
      "Training MAE :16.441148782508996\n",
      "Weights are :   [29.59325092 94.6498734   8.37477612 45.52253038  2.46429201]\n",
      "Bias is :  0.318833231782387\n",
      "\n",
      "Epochs113\n",
      "Training cost :207.77665850750338\n",
      "Training MAE :16.441149749973626\n",
      "Weights are :   [29.59328319 94.6499508   8.37483606 45.52257869  2.46431956]\n",
      "Bias is :  0.3188334470457299\n",
      "\n",
      "Epochs114\n",
      "Training cost :207.77665837675323\n",
      "Training MAE :16.44115063123422\n",
      "Weights are :   [29.5933124  94.65002073  8.37489064 45.52262238  2.46434478]\n",
      "Bias is :  0.3188336407827383\n",
      "\n",
      "Epochs115\n",
      "Training cost :207.77665826935217\n",
      "Training MAE :16.44115143390569\n",
      "Weights are :   [29.59333885 94.6500839   8.37494035 45.5226619   2.46436787]\n",
      "Bias is :  0.318833815146046\n",
      "\n",
      "Epochs116\n",
      "Training cost :207.7766581811246\n",
      "Training MAE :16.441152164937844\n",
      "Weights are :   [29.59336279 94.65014098  8.37498562 45.52269763  2.46438901]\n",
      "Bias is :  0.31883397207302316\n",
      "\n",
      "Epochs117\n",
      "Training cost :207.7766581086425\n",
      "Training MAE :16.441152830672564\n",
      "Weights are :   [29.59338446 94.65019255  8.37502684 45.52272996  2.46440836]\n",
      "Bias is :  0.3188341133073021\n",
      "\n",
      "Epochs118\n",
      "Training cost :207.77665804909194\n",
      "Training MAE :16.441153436896236\n",
      "Weights are :   [29.59340408 94.65023914  8.37506437 45.52275919  2.46442608]\n",
      "Bias is :  0.3188342404181534\n",
      "\n",
      "Epochs119\n",
      "Training cost :207.7766580001625\n",
      "Training MAE :16.44115398888774\n",
      "Weights are :   [29.59342185 94.65028124  8.37509854 45.52278564  2.46444229]\n",
      "Bias is :  0.3188343548179199\n",
      "\n",
      "Epochs120\n",
      "Training cost :207.77665795995722\n",
      "Training MAE :16.441154491462346\n",
      "Weights are :   [29.59343793 94.65031928  8.37512965 45.52280956  2.46445713]\n",
      "Bias is :  0.3188344577777096\n",
      "\n",
      "Epochs121\n",
      "Training cost :207.77665792691838\n",
      "Training MAE :16.441154949011885\n",
      "Weights are :   [29.59345249 94.65035365  8.37515798 45.52283119  2.46447071]\n",
      "Bias is :  0.31883455044152\n",
      "\n",
      "Epochs122\n",
      "Training cost :207.77665789976683\n",
      "Training MAE :16.441155365541547\n",
      "Weights are :   [29.59346568 94.65038471  8.37518376 45.52285076  2.46448314]\n",
      "Bias is :  0.31883463383894933\n",
      "\n",
      "Epochs123\n",
      "Training cost :207.7766578774521\n",
      "Training MAE :16.441155744703476\n",
      "Weights are :   [29.59347761 94.65041278  8.37520724 45.52286846  2.46449451]\n",
      "Bias is :  0.31883470889663623\n",
      "\n",
      "Epochs124\n",
      "Training cost :207.77665785911145\n",
      "Training MAE :16.441156089827526\n",
      "Weights are :   [29.59348842 94.65043815  8.37522861 45.52288447  2.46450491]\n",
      "Bias is :  0.31883477644855407\n",
      "\n",
      "Epochs125\n",
      "Training cost :207.77665784403607\n",
      "Training MAE :16.441156403949382\n",
      "Weights are :   [29.5934982  94.65046107  8.37524806 45.52289895  2.46451442]\n",
      "Bias is :  0.3188348372452805\n",
      "\n",
      "Epochs126\n",
      "Training cost :207.77665783164394\n",
      "Training MAE :16.44115668983624\n",
      "Weights are :   [29.59350706 94.65048179  8.37526577 45.52291205  2.46452312]\n",
      "Bias is :  0.3188348919623342\n",
      "\n",
      "Epochs127\n",
      "Training cost :207.77665782145684\n",
      "Training MAE :16.441156950010317\n",
      "Weights are :   [29.59351508 94.65050051  8.37528188 45.52292389  2.46453108]\n",
      "Bias is :  0.3188349412076824\n",
      "\n",
      "Epochs128\n",
      "Training cost :207.77665781308187\n",
      "Training MAE :16.441157186770283\n",
      "Weights are :   [29.59352235 94.65051744  8.37529655 45.52293461  2.46453836]\n",
      "Bias is :  0.31883498552849565\n",
      "\n",
      "Epochs129\n",
      "Training cost :207.7766578061963\n",
      "Training MAE :16.441157402210916\n",
      "Weights are :   [29.59352892 94.65053274  8.3753099  45.52294431  2.46454502]\n",
      "Bias is :  0.3188350254172276\n",
      "\n",
      "Epochs130\n",
      "Training cost :207.77665780053496\n",
      "Training MAE :16.441157598240952\n",
      "Weights are :   [29.59353488 94.65054656  8.37532205 45.52295308  2.4645511 ]\n",
      "Bias is :  0.3188350613170863\n",
      "\n",
      "Epochs131\n",
      "Training cost :207.77665779587988\n",
      "Training MAE :16.4411577765995\n",
      "Weights are :   [29.59354027 94.65055906  8.37533311 45.52296101  2.46455667]\n",
      "Bias is :  0.3188350936269591\n",
      "\n",
      "Epochs132\n",
      "Training cost :207.776657792052\n",
      "Training MAE :16.44115793887093\n",
      "Weights are :   [29.59354515 94.65057036  8.37534318 45.52296819  2.46456176]\n",
      "Bias is :  0.3188351227058446\n",
      "\n",
      "Epochs133\n",
      "Training cost :207.77665778890412\n",
      "Training MAE :16.441158086498568\n",
      "Weights are :   [29.59354957 94.65058057  8.37535233 45.52297468  2.46456641]\n",
      "Bias is :  0.3188351488768415\n",
      "\n",
      "Epochs134\n",
      "Training cost :207.77665778631538\n",
      "Training MAE :16.441158220797092\n",
      "Weights are :   [29.59355358 94.65058981  8.37536067 45.52298056  2.46457066]\n",
      "Bias is :  0.31883517243073883\n",
      "\n",
      "Epochs135\n",
      "Training cost :207.77665778418626\n",
      "Training MAE :16.441158342963924\n",
      "Weights are :   [29.5935572  94.65059815  8.37536825 45.52298587  2.46457454]\n",
      "Bias is :  0.3188351936292466\n",
      "\n",
      "Epochs136\n",
      "Training cost :207.77665778243508\n",
      "Training MAE :16.441158454089596\n",
      "Weights are :   [29.59356048 94.6506057   8.37537515 45.52299068  2.4645781 ]\n",
      "Bias is :  0.3188352127079038\n",
      "\n",
      "Epochs137\n",
      "Training cost :207.7766577809947\n",
      "Training MAE :16.44115855516723\n",
      "Weights are :   [29.59356345 94.65061252  8.37538143 45.52299503  2.46458134]\n",
      "Bias is :  0.3188352298786947\n",
      "\n",
      "Epochs138\n",
      "Training cost :207.77665777980982\n",
      "Training MAE :16.44115864710114\n",
      "Weights are :   [29.59356615 94.65061869  8.37538715 45.52299896  2.46458431]\n",
      "Bias is :  0.31883524533240687\n",
      "\n",
      "Epochs139\n",
      "Training cost :207.7766577788352\n",
      "Training MAE :16.44115873071474\n",
      "Weights are :   [29.59356858 94.65062427  8.37539235 45.52300252  2.46458702]\n",
      "Bias is :  0.31883525924074785\n",
      "\n",
      "Epochs140\n",
      "Training cost :207.7766577780334\n",
      "Training MAE :16.441158806757713\n",
      "Weights are :   [29.59357079 94.65062931  8.37539708 45.52300574  2.4645895 ]\n",
      "Bias is :  0.31883527175825455\n",
      "\n",
      "Epochs141\n",
      "Training cost :207.77665777737377\n",
      "Training MAE :16.441158875912567\n",
      "Weights are :   [29.59357279 94.65063387  8.37540138 45.52300865  2.46459176]\n",
      "Bias is :  0.3188352830240107\n",
      "\n",
      "Epochs142\n",
      "Training cost :207.77665777683106\n",
      "Training MAE :16.441158938800612\n",
      "Weights are :   [29.5935746  94.65063799  8.3754053  45.52301129  2.46459383]\n",
      "Bias is :  0.3188352931631911\n",
      "\n",
      "Epochs143\n",
      "Training cost :207.7766577763845\n",
      "Training MAE :16.441158995987426\n",
      "Weights are :   [29.59357624 94.65064172  8.37540886 45.52301367  2.46459571]\n",
      "Bias is :  0.31883530228845336\n",
      "\n",
      "Epochs144\n",
      "Training cost :207.7766577760171\n",
      "Training MAE :16.441159047987785\n",
      "Weights are :   [29.59357772 94.65064509  8.3754121  45.52301583  2.46459744]\n",
      "Bias is :  0.3188353105011898\n",
      "\n",
      "Epochs145\n",
      "Training cost :207.77665777571474\n",
      "Training MAE :16.44115909527024\n",
      "Weights are :   [29.59357907 94.65064814  8.37541505 45.52301778  2.46459902]\n",
      "Bias is :  0.31883531789265257\n",
      "\n",
      "Epochs146\n",
      "Training cost :207.77665777546594\n",
      "Training MAE :16.441159138261195\n",
      "Weights are :   [29.59358029 94.6506509   8.37541773 45.52301955  2.46460045]\n",
      "Bias is :  0.31883532454496916\n",
      "\n",
      "Epochs147\n",
      "Training cost :207.77665777526119\n",
      "Training MAE :16.441159177348723\n",
      "Weights are :   [29.59358139 94.65065339  8.37542017 45.52302115  2.46460177]\n",
      "Bias is :  0.31883533053205376\n",
      "\n",
      "Epochs148\n",
      "Training cost :207.77665777509273\n",
      "Training MAE :16.44115921288595\n",
      "Weights are :   [29.59358239 94.65065565  8.37542239 45.52302259  2.46460297]\n",
      "Bias is :  0.3188353359204297\n",
      "\n",
      "Epochs149\n",
      "Training cost :207.776657774954\n",
      "Training MAE :16.441159245194214\n",
      "Weights are :   [29.59358329 94.65065769  8.37542441 45.5230239   2.46460407]\n",
      "Bias is :  0.31883534076996844\n",
      "\n",
      "Epochs150\n",
      "Training cost :207.7766577748399\n",
      "Training MAE :16.44115927456588\n",
      "Weights are :   [29.59358411 94.65065953  8.37542624 45.52302509  2.46460507]\n",
      "Bias is :  0.31883534513455347\n",
      "\n",
      "Epochs151\n",
      "Training cost :207.77665777474598\n",
      "Training MAE :16.441159301266975\n",
      "Weights are :   [29.59358485 94.6506612   8.37542791 45.52302616  2.46460598]\n",
      "Bias is :  0.3188353490626797\n",
      "\n",
      "Epochs152\n",
      "Training cost :207.77665777466865\n",
      "Training MAE :16.441159325539513\n",
      "Weights are :   [29.59358552 94.65066271  8.37542943 45.52302713  2.46460681]\n",
      "Bias is :  0.31883535259799317\n",
      "\n",
      "Epochs153\n",
      "Training cost :207.77665777460498\n",
      "Training MAE :16.44115934760367\n",
      "Weights are :   [29.59358613 94.65066408  8.37543081 45.523028    2.46460758]\n",
      "Bias is :  0.31883535577977545\n",
      "\n",
      "Epochs154\n",
      "Training cost :207.7766577745526\n",
      "Training MAE :16.441159367659747\n",
      "Weights are :   [29.59358668 94.65066531  8.37543207 45.5230288   2.46460827]\n",
      "Bias is :  0.3188353586433792\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs155\n",
      "Training cost :207.77665777450943\n",
      "Training MAE :16.441159385889936\n",
      "Weights are :   [29.59358718 94.65066643  8.37543322 45.52302951  2.46460891]\n",
      "Bias is :  0.31883536122062267\n",
      "\n",
      "Epochs156\n",
      "Training cost :207.77665777447393\n",
      "Training MAE :16.441159402459977\n",
      "Weights are :   [29.59358764 94.65066744  8.37543425 45.52303016  2.46460949]\n",
      "Bias is :  0.31883536354014175\n",
      "\n",
      "Epochs157\n",
      "Training cost :207.7766577744447\n",
      "Training MAE :16.44115941752061\n",
      "Weights are :   [29.59358805 94.65066836  8.3754352  45.52303075  2.46461002]\n",
      "Bias is :  0.31883536562770937\n",
      "\n",
      "Epochs158\n",
      "Training cost :207.7766577744206\n",
      "Training MAE :16.441159431208927\n",
      "Weights are :   [29.59358842 94.65066918  8.37543606 45.52303128  2.4646105 ]\n",
      "Bias is :  0.31883536750652025\n",
      "\n",
      "Epochs159\n",
      "Training cost :207.7766577744008\n",
      "Training MAE :16.441159443649646\n",
      "Weights are :   [29.59358875 94.65066993  8.37543684 45.52303177  2.46461094]\n",
      "Bias is :  0.31883536919744965\n",
      "\n",
      "Epochs160\n",
      "Training cost :207.77665777438443\n",
      "Training MAE :16.441159454956157\n",
      "Weights are :   [29.59358906 94.65067061  8.37543755 45.5230322   2.46461134]\n",
      "Bias is :  0.31883537071928647\n",
      "\n",
      "Epochs161\n",
      "Training cost :207.77665777437105\n",
      "Training MAE :16.44115946523159\n",
      "Weights are :   [29.59358933 94.65067122  8.3754382  45.5230326   2.46461171]\n",
      "Bias is :  0.31883537208893953\n",
      "\n",
      "Epochs162\n",
      "Training cost :207.77665777435996\n",
      "Training MAE :16.441159474569737\n",
      "Weights are :   [29.59358958 94.65067178  8.37543879 45.52303295  2.46461204]\n",
      "Bias is :  0.31883537332162737\n",
      "\n",
      "Epochs163\n",
      "Training cost :207.77665777435087\n",
      "Training MAE :16.441159483055877\n",
      "Weights are :   [29.59358981 94.65067228  8.37543933 45.52303328  2.46461235]\n",
      "Bias is :  0.3188353744310459\n",
      "\n",
      "Epochs164\n",
      "Training cost :207.77665777434333\n",
      "Training MAE :16.44115949076755\n",
      "Weights are :   [29.59359001 94.65067273  8.37543981 45.52303357  2.46461263]\n",
      "Bias is :  0.3188353754295229\n",
      "\n",
      "Epochs165\n",
      "Training cost :207.7766577743372\n",
      "Training MAE :16.441159497775274\n",
      "Weights are :   [29.5935902  94.65067314  8.37544025 45.52303383  2.46461288]\n",
      "Bias is :  0.3188353763281519\n",
      "\n",
      "Epochs166\n",
      "Training cost :207.77665777433205\n",
      "Training MAE :16.441159504143148\n",
      "Weights are :   [29.59359037 94.65067352  8.37544066 45.52303407  2.46461311]\n",
      "Bias is :  0.31883537713691856\n",
      "\n",
      "Epochs167\n",
      "Training cost :207.7766577743279\n",
      "Training MAE :16.44115950992947\n",
      "Weights are :   [29.59359052 94.65067385  8.37544102 45.52303429  2.46461333]\n",
      "Bias is :  0.3188353778648084\n",
      "\n",
      "Epochs168\n",
      "Training cost :207.77665777432446\n",
      "Training MAE :16.441159515187227\n",
      "Weights are :   [29.59359066 94.65067416  8.37544136 45.52303448  2.46461352]\n",
      "Bias is :  0.31883537851990884\n",
      "\n",
      "Epochs169\n",
      "Training cost :207.7766577743216\n",
      "Training MAE :16.441159519964593\n",
      "Weights are :   [29.59359078 94.65067443  8.37544166 45.52303466  2.46461369]\n",
      "Bias is :  0.31883537910949966\n",
      "\n",
      "Epochs170\n",
      "Training cost :207.77665777431926\n",
      "Training MAE :16.441159524305377\n",
      "Weights are :   [29.59359089 94.65067468  8.37544193 45.52303482  2.46461386]\n",
      "Bias is :  0.31883537964013153\n",
      "\n",
      "Epochs171\n",
      "Training cost :207.77665777431736\n",
      "Training MAE :16.441159528249386\n",
      "Weights are :   [29.593591   94.65067491  8.37544218 45.52303497  2.464614  ]\n",
      "Bias is :  0.3188353801177001\n",
      "\n",
      "Epochs172\n",
      "Training cost :207.77665777431577\n",
      "Training MAE :16.441159531832813\n",
      "Weights are :   [29.59359109 94.65067511  8.37544241 45.5230351   2.46461414]\n",
      "Bias is :  0.31883538054751176\n",
      "\n",
      "Epochs173\n",
      "Training cost :207.77665777431446\n",
      "Training MAE :16.441159535088563\n",
      "Weights are :   [29.59359117 94.6506753   8.37544262 45.52303522  2.46461426]\n",
      "Bias is :  0.31883538093434216\n",
      "\n",
      "Epochs174\n",
      "Training cost :207.77665777431335\n",
      "Training MAE :16.44115953804654\n",
      "Weights are :   [29.59359125 94.65067546  8.37544281 45.52303533  2.46461437]\n",
      "Bias is :  0.3188353812824896\n",
      "\n",
      "Epochs175\n",
      "Training cost :207.7766577743125\n",
      "Training MAE :16.44115954073393\n",
      "Weights are :   [29.59359132 94.65067561  8.37544298 45.52303542  2.46461447]\n",
      "Bias is :  0.3188353815958222\n",
      "\n",
      "Epochs176\n",
      "Training cost :207.77665777431173\n",
      "Training MAE :16.441159543175438\n",
      "Weights are :   [29.59359138 94.65067575  8.37544313 45.52303551  2.46461456]\n",
      "Bias is :  0.31883538187782173\n",
      "\n",
      "Epochs177\n",
      "Training cost :207.7766577743111\n",
      "Training MAE :16.441159545393518\n",
      "Weights are :   [29.59359144 94.65067588  8.37544327 45.52303559  2.46461465]\n",
      "Bias is :  0.3188353821316214\n",
      "\n",
      "Epochs178\n",
      "Training cost :207.77665777431068\n",
      "Training MAE :16.441159547408578\n",
      "Weights are :   [29.59359149 94.65067599  8.3754434  45.52303566  2.46461472]\n",
      "Bias is :  0.31883538236004055\n",
      "\n",
      "Epochs179\n",
      "Training cost :207.77665777431022\n",
      "Training MAE :16.441159549239178\n",
      "Weights are :   [29.59359154 94.65067609  8.37544352 45.52303573  2.46461479]\n",
      "Bias is :  0.31883538256561805\n",
      "\n",
      "Epochs180\n",
      "Training cost :207.7766577743099\n",
      "Training MAE :16.441159550902167\n",
      "Weights are :   [29.59359158 94.65067618  8.37544363 45.52303579  2.46461486]\n",
      "Bias is :  0.31883538275063755\n",
      "\n",
      "Epochs181\n",
      "Training cost :207.7766577743096\n",
      "Training MAE :16.44115955241287\n",
      "Weights are :   [29.59359162 94.65067627  8.37544372 45.52303584  2.46461492]\n",
      "Bias is :  0.31883538291715524\n",
      "\n",
      "Epochs182\n",
      "Training cost :207.7766577743094\n",
      "Training MAE :16.44115955378521\n",
      "Weights are :   [29.59359165 94.65067634  8.37544381 45.52303589  2.46461497]\n",
      "Bias is :  0.3188353830670214\n",
      "\n",
      "Epochs183\n",
      "Training cost :207.7766577743092\n",
      "Training MAE :16.44115955503184\n",
      "Weights are :   [29.59359168 94.65067641  8.37544389 45.52303593  2.46461502]\n",
      "Bias is :  0.318835383201901\n",
      "\n",
      "Epochs184\n",
      "Training cost :207.77665777430903\n",
      "Training MAE :16.44115955616425\n",
      "Weights are :   [29.59359171 94.65067647  8.37544396 45.52303597  2.46461506]\n",
      "Bias is :  0.31883538332329253\n",
      "\n",
      "Epochs185\n",
      "Training cost :207.77665777430892\n",
      "Training MAE :16.441159557192908\n",
      "Weights are :   [29.59359174 94.65067653  8.37544403 45.52303601  2.4646151 ]\n",
      "Bias is :  0.3188353834325451\n",
      "\n",
      "Epochs186\n",
      "Training cost :207.77665777430877\n",
      "Training MAE :16.44115955812729\n",
      "Weights are :   [29.59359176 94.65067658  8.37544409 45.52303604  2.46461514]\n",
      "Bias is :  0.3188353835308723\n",
      "\n",
      "Epochs187\n",
      "Training cost :207.7766577743087\n",
      "Training MAE :16.441159558976025\n",
      "Weights are :   [29.59359178 94.65067662  8.37544414 45.52303607  2.46461517]\n",
      "Bias is :  0.3188353836193666\n",
      "\n",
      "Epochs188\n",
      "Training cost :207.77665777430863\n",
      "Training MAE :16.44115955974696\n",
      "Weights are :   [29.5935918  94.65067667  8.37544419 45.5230361   2.4646152 ]\n",
      "Bias is :  0.31883538369901154\n",
      "\n",
      "Epochs189\n",
      "Training cost :207.7766577743086\n",
      "Training MAE :16.44115956044721\n",
      "Weights are :   [29.59359182 94.6506767   8.37544424 45.52303612  2.46461523]\n",
      "Bias is :  0.3188353837706917\n",
      "\n",
      "Epochs190\n",
      "Training cost :207.77665777430852\n",
      "Training MAE :16.441159561083257\n",
      "Weights are :   [29.59359183 94.65067674  8.37544428 45.52303615  2.46461526]\n",
      "Bias is :  0.31883538383520393\n",
      "\n",
      "Epochs191\n",
      "Training cost :207.7766577743085\n",
      "Training MAE :16.44115956166097\n",
      "Weights are :   [29.59359185 94.65067677  8.37544432 45.52303617  2.46461528]\n",
      "Bias is :  0.31883538389326516\n",
      "\n",
      "Epochs192\n",
      "Training cost :207.7766577743085\n",
      "Training MAE :16.4411595621857\n",
      "Weights are :   [29.59359186 94.6506768   8.37544435 45.52303618  2.4646153 ]\n",
      "Bias is :  0.3188353839455205\n",
      "\n",
      "Epochs193\n",
      "Training cost :207.7766577743084\n",
      "Training MAE :16.441159562662293\n",
      "Weights are :   [29.59359187 94.65067682  8.37544438 45.5230362   2.46461532]\n",
      "Bias is :  0.31883538399254985\n",
      "\n",
      "Epochs194\n",
      "Training cost :207.7766577743084\n",
      "Training MAE :16.441159563095162\n",
      "Weights are :   [29.59359188 94.65067684  8.37544441 45.52303621  2.46461534]\n",
      "Bias is :  0.3188353840348761\n",
      "\n",
      "Epochs195\n",
      "Training cost :207.7766577743084\n",
      "Training MAE :16.441159563488316\n",
      "Weights are :   [29.59359189 94.65067686  8.37544443 45.52303623  2.46461535]\n",
      "Bias is :  0.31883538407297013\n",
      "\n",
      "Epochs196\n",
      "Training cost :207.7766577743084\n",
      "Training MAE :16.441159563845396\n",
      "Weights are :   [29.5935919  94.65067688  8.37544446 45.52303624  2.46461537]\n",
      "Bias is :  0.3188353841072547\n",
      "\n",
      "Epochs197\n",
      "Training cost :207.77665777430838\n",
      "Training MAE :16.441159564169702\n",
      "Weights are :   [29.59359191 94.6506769   8.37544448 45.52303625  2.46461538]\n",
      "Bias is :  0.31883538413811086\n",
      "\n",
      "Epochs198\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159564464243\n",
      "Weights are :   [29.59359192 94.65067692  8.3754445  45.52303626  2.46461539]\n",
      "Bias is :  0.31883538416588136\n",
      "\n",
      "Epochs199\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956473175\n",
      "Weights are :   [29.59359192 94.65067693  8.37544451 45.52303627  2.4646154 ]\n",
      "Bias is :  0.3188353841908749\n",
      "\n",
      "Epochs200\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159564974697\n",
      "Weights are :   [29.59359193 94.65067694  8.37544453 45.52303628  2.46461541]\n",
      "Bias is :  0.31883538421336916\n",
      "\n",
      "Epochs201\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159565195342\n",
      "Weights are :   [29.59359193 94.65067695  8.37544454 45.52303628  2.46461542]\n",
      "Bias is :  0.3188353842336137\n",
      "\n",
      "Epochs202\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159565395726\n",
      "Weights are :   [29.59359194 94.65067696  8.37544456 45.52303629  2.46461543]\n",
      "Bias is :  0.3188353842518341\n",
      "\n",
      "Epochs203\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159565577706\n",
      "Weights are :   [29.59359194 94.65067697  8.37544457 45.5230363   2.46461544]\n",
      "Bias is :  0.31883538426823227\n",
      "\n",
      "Epochs204\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956574298\n",
      "Weights are :   [29.59359195 94.65067698  8.37544458 45.5230363   2.46461545]\n",
      "Bias is :  0.31883538428299085\n",
      "\n",
      "Epochs205\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159565893066\n",
      "Weights are :   [29.59359195 94.65067699  8.37544459 45.52303631  2.46461545]\n",
      "Bias is :  0.31883538429627367\n",
      "\n",
      "Epochs206\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956602937\n",
      "Weights are :   [29.59359195 94.650677    8.3754446  45.52303631  2.46461546]\n",
      "Bias is :  0.31883538430822767\n",
      "\n",
      "Epochs207\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159566153157\n",
      "Weights are :   [29.59359196 94.650677    8.37544461 45.52303632  2.46461546]\n",
      "Bias is :  0.31883538431898667\n",
      "\n",
      "Epochs208\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159566265565\n",
      "Weights are :   [29.59359196 94.65067701  8.37544461 45.52303632  2.46461547]\n",
      "Bias is :  0.31883538432866954\n",
      "\n",
      "Epochs209\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956636765\n",
      "Weights are :   [29.59359196 94.65067701  8.37544462 45.52303632  2.46461547]\n",
      "Bias is :  0.318835384337384\n",
      "\n",
      "Epochs210\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956646035\n",
      "Weights are :   [29.59359196 94.65067702  8.37544463 45.52303633  2.46461548]\n",
      "Bias is :  0.3188353843452272\n",
      "\n",
      "Epochs211\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956654454\n",
      "Weights are :   [29.59359197 94.65067702  8.37544463 45.52303633  2.46461548]\n",
      "Bias is :  0.3188353843522864\n",
      "\n",
      "Epochs212\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159566620986\n",
      "Weights are :   [29.59359197 94.65067703  8.37544464 45.52303633  2.46461548]\n",
      "Bias is :  0.31883538435863934\n",
      "\n",
      "Epochs213\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956669041\n",
      "Weights are :   [29.59359197 94.65067703  8.37544464 45.52303633  2.46461549]\n",
      "Bias is :  0.3188353843643571\n",
      "\n",
      "Epochs214\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956675345\n",
      "Weights are :   [29.59359197 94.65067703  8.37544465 45.52303634  2.46461549]\n",
      "Bias is :  0.318835384369503\n",
      "\n",
      "Epochs215\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159566810697\n",
      "Weights are :   [29.59359197 94.65067704  8.37544465 45.52303634  2.46461549]\n",
      "Bias is :  0.31883538437413445\n",
      "\n",
      "Epochs216\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956686268\n",
      "Weights are :   [29.59359197 94.65067704  8.37544465 45.52303634  2.46461549]\n",
      "Bias is :  0.3188353843783026\n",
      "\n",
      "Epochs217\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956690988\n",
      "Weights are :   [29.59359197 94.65067704  8.37544466 45.52303634  2.4646155 ]\n",
      "Bias is :  0.31883538438205383\n",
      "\n",
      "Epochs218\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956695275\n",
      "Weights are :   [29.59359197 94.65067704  8.37544466 45.52303634  2.4646155 ]\n",
      "Bias is :  0.3188353843854299\n",
      "\n",
      "Epochs219\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159566991672\n",
      "Weights are :   [29.59359198 94.65067705  8.37544466 45.52303634  2.4646155 ]\n",
      "Bias is :  0.3188353843884686\n",
      "\n",
      "Epochs220\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567027018\n",
      "Weights are :   [29.59359198 94.65067705  8.37544466 45.52303634  2.4646155 ]\n",
      "Bias is :  0.3188353843912032\n",
      "\n",
      "Epochs221\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567059113\n",
      "Weights are :   [29.59359198 94.65067705  8.37544467 45.52303635  2.4646155 ]\n",
      "Bias is :  0.3188353843936643\n",
      "\n",
      "Epochs222\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567088256\n",
      "Weights are :   [29.59359198 94.65067705  8.37544467 45.52303635  2.4646155 ]\n",
      "Bias is :  0.3188353843958797\n",
      "\n",
      "Epochs223\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956711472\n",
      "Weights are :   [29.59359198 94.65067705  8.37544467 45.52303635  2.4646155 ]\n",
      "Bias is :  0.31883538439787346\n",
      "\n",
      "Epochs224\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956713875\n",
      "Weights are :   [29.59359198 94.65067705  8.37544467 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353843996675\n",
      "\n",
      "Epochs225\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567160568\n",
      "Weights are :   [29.59359198 94.65067705  8.37544467 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844012823\n",
      "\n",
      "Epochs226\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956718038\n",
      "Weights are :   [29.59359198 94.65067706  8.37544467 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538440273596\n",
      "\n",
      "Epochs227\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567198373\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844040438\n",
      "\n",
      "Epochs228\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567214708\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844052208\n",
      "\n",
      "Epochs229\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956722954\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844062804\n",
      "\n",
      "Epochs230\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956724301\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844072341\n",
      "\n",
      "Epochs231\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567255237\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538440809206\n",
      "\n",
      "Epochs232\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956726634\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844088646\n",
      "\n",
      "Epochs233\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567276422\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844095597\n",
      "\n",
      "Epochs234\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567285577\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441018533\n",
      "\n",
      "Epochs235\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956729389\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441074843\n",
      "\n",
      "Epochs236\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567301437\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441125503\n",
      "\n",
      "Epochs237\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956730829\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844117111\n",
      "\n",
      "Epochs238\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956731451\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844121217\n",
      "\n",
      "Epochs239\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956732016\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844124909\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs240\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956732529\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844128233\n",
      "\n",
      "Epochs241\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567329947\n",
      "Weights are :   [29.59359198 94.65067706  8.37544468 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441312237\n",
      "\n",
      "Epochs242\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956733418\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844133918\n",
      "\n",
      "Epochs243\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567338016\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441363407\n",
      "\n",
      "Epochs244\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.4411595673415\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441385245\n",
      "\n",
      "Epochs245\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567344666\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441404846\n",
      "\n",
      "Epochs246\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956734754\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.3188353844142251\n",
      "\n",
      "Epochs247\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956735015\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441438386\n",
      "\n",
      "Epochs248\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956735252\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461551]\n",
      "Bias is :  0.31883538441452725\n",
      "\n",
      "Epochs249\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956735467\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441465586\n",
      "\n",
      "Epochs250\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567356625\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844147719\n",
      "\n",
      "Epochs251\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.4411595673584\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441487647\n",
      "\n",
      "Epochs252\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567360007\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441497017\n",
      "\n",
      "Epochs253\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956736147\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441505493\n",
      "\n",
      "Epochs254\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567362796\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441513115\n",
      "\n",
      "Epochs255\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567364004\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844151992\n",
      "\n",
      "Epochs256\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567365098\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441526105\n",
      "\n",
      "Epochs257\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956736609\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441531656\n",
      "\n",
      "Epochs258\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956736699\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844153665\n",
      "\n",
      "Epochs259\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956736781\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441541154\n",
      "\n",
      "Epochs260\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956736855\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844154518\n",
      "\n",
      "Epochs261\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567369226\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441548825\n",
      "\n",
      "Epochs262\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956736984\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441552106\n",
      "\n",
      "Epochs263\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567370395\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441555076\n",
      "\n",
      "Epochs264\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567370907\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415577\n",
      "\n",
      "Epochs265\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737136\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441560105\n",
      "\n",
      "Epochs266\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567371777\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441562254\n",
      "\n",
      "Epochs267\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567372157\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441564196\n",
      "\n",
      "Epochs268\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567372498\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441565934\n",
      "\n",
      "Epochs269\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737281\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844156751\n",
      "\n",
      "Epochs270\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737309\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441568904\n",
      "\n",
      "Epochs271\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737335\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441570175\n",
      "\n",
      "Epochs272\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567373585\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441571296\n",
      "\n",
      "Epochs273\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567373795\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441572357\n",
      "\n",
      "Epochs274\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567373987\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157327\n",
      "\n",
      "Epochs275\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737416\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441574094\n",
      "\n",
      "Epochs276\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737432\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441574866\n",
      "\n",
      "Epochs277\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567374463\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157556\n",
      "\n",
      "Epochs278\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567374594\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441576165\n",
      "\n",
      "Epochs279\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737471\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441576686\n",
      "\n",
      "Epochs280\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737482\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441577186\n",
      "\n",
      "Epochs281\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737492\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157763\n",
      "\n",
      "Epochs282\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375006\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157805\n",
      "\n",
      "Epochs283\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375088\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415784\n",
      "\n",
      "Epochs284\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375163\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441578724\n",
      "\n",
      "Epochs285\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375227\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441578996\n",
      "\n",
      "Epochs286\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375287\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441579246\n",
      "\n",
      "Epochs287\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375344\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441579484\n",
      "\n",
      "Epochs288\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375394\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157971\n",
      "\n",
      "Epochs289\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737544\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844157992\n",
      "\n",
      "Epochs290\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737548\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158008\n",
      "\n",
      "Epochs291\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375518\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158023\n",
      "\n",
      "Epochs292\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737555\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441580367\n",
      "\n",
      "Epochs293\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375582\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415805\n",
      "\n",
      "Epochs294\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375607\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158063\n",
      "\n",
      "Epochs295\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737563\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441580694\n",
      "\n",
      "Epochs296\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375657\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158076\n",
      "\n",
      "Epochs297\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375678\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158082\n",
      "\n",
      "Epochs298\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375696\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441580883\n",
      "\n",
      "Epochs299\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375713\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158094\n",
      "\n",
      "Epochs300\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375728\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158099\n",
      "\n",
      "Epochs301\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375745\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158103\n",
      "\n",
      "Epochs302\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375752\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581066\n",
      "\n",
      "Epochs303\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375767\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581105\n",
      "\n",
      "Epochs304\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375777\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158115\n",
      "\n",
      "Epochs305\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375788\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158119\n",
      "\n",
      "Epochs306\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375795\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158123\n",
      "\n",
      "Epochs307\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375802\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158126\n",
      "\n",
      "Epochs308\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375813\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs309\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375816\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs310\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375827\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs311\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737583\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs312\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375834\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs313\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737584\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs314\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375845\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs315\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375845\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs316\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737585\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs317\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375852\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs318\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375852\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581316\n",
      "\n",
      "Epochs319\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737586\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs320\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375863\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs321\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375863\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs322\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375866\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs323\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375866\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs324\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375866\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs325\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737587\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs326\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737587\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581327\n",
      "\n",
      "Epochs327\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737587\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs328\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737587\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs329\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737587\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs330\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs331\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375873\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs332\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs333\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs334\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs335\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs336\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs337\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs338\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs339\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs340\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.441159567375877\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs341\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs342\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs343\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs344\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs345\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs346\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs347\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs348\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs349\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs350\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs351\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs352\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs353\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs354\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs355\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs356\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs357\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs358\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs359\n",
      "Training cost :207.77665777430826\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs360\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs361\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs362\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs363\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs364\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs365\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs366\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs367\n",
      "Training cost :207.77665777430835\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581305\n",
      "\n",
      "Epochs368\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158129\n",
      "\n",
      "Epochs369\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158132\n",
      "\n",
      "Epochs370\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs371\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs372\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs373\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581316\n",
      "\n",
      "Epochs374\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs375\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs376\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs377\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs378\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs379\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.44115956737588\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs380\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs381\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs382\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs383\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs384\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs385\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs386\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs387\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs388\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs389\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs390\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs391\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs392\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs393\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs394\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs395\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs396\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs397\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs398\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs399\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs400\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs401\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs402\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs403\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs404\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs405\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs406\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs407\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs408\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs409\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs410\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs411\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs412\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs413\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs414\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs415\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs416\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs417\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs418\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs419\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs420\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs421\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs422\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs423\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs424\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs425\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs426\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs427\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs428\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs429\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs430\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs431\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs432\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs433\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs434\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs435\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs436\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs437\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs438\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs439\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs440\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs441\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs442\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs443\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs444\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs445\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs446\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs447\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs448\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs449\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs450\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs451\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs452\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs453\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs454\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs455\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs456\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs457\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs458\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs459\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs460\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs461\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs462\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs463\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs464\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs465\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs466\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs467\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs468\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs469\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs470\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs471\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs472\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs473\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs474\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs475\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs476\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs477\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs478\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs479\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs480\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs481\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs482\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs483\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs484\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs485\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs486\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs487\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs488\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs489\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs490\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs491\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs492\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs493\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs494\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs495\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs496\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs497\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs498\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs499\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs500\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs501\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs502\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs503\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs504\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs505\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs506\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs507\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs508\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs509\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs510\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs511\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs512\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs513\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs514\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs515\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs516\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs517\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs518\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs519\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs520\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs521\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs522\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs523\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs524\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs525\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs526\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs527\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs528\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs529\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs530\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs531\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs532\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs533\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs534\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs535\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs536\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs537\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs538\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs539\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs540\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs541\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs542\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs543\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs544\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs545\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs546\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs547\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs548\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs549\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs550\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs551\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs552\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs553\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs554\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs555\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs556\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs557\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs558\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs559\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs560\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs561\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs562\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs563\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs564\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs565\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs566\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs567\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs568\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs569\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs570\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs571\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs572\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs573\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs574\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs575\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs576\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs577\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs578\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs579\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs580\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs581\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs582\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs583\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs584\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs585\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs586\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs587\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs588\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs589\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs590\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs591\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs592\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs593\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs594\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs595\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs596\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs597\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs598\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs599\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs600\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs601\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs602\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs603\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs604\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs605\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs606\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs607\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs608\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs609\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs610\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs611\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs612\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs613\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs614\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs615\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs616\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs617\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs618\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs619\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs620\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs621\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs622\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs623\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs624\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs625\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs626\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs627\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs628\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs629\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs630\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs631\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs632\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs633\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs634\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs635\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs636\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs637\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs638\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs639\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs640\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs641\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs642\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs643\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs644\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs645\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs646\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs647\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs648\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs649\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs650\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs651\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs652\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs653\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs654\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs655\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs656\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs657\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs658\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs659\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs660\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs661\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs662\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs663\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs664\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs665\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs666\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs667\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs668\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs669\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs670\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs671\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs672\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs673\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs674\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs675\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs676\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs677\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs678\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs679\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs680\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs681\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs682\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs683\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs684\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs685\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs686\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs687\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs688\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs689\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs690\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs691\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs692\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs693\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs694\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs695\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs696\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs697\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs698\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs699\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs700\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs701\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs702\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs703\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs704\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs705\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs706\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs707\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs708\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs709\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs710\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs711\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs712\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs713\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs714\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs715\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs716\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs717\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs718\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs719\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs720\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs721\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs722\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs723\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs724\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs725\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs726\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs727\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs728\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs729\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs730\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs731\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs732\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs733\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs734\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs735\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs736\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs737\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs738\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs739\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs740\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs741\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs742\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs743\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs744\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs745\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs746\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs747\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs748\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs749\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs750\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs751\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs752\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs753\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs754\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs755\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs756\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs757\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs758\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs759\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs760\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs761\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs762\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs763\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs764\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs765\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs766\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs767\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs768\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs769\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs770\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs771\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs772\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs773\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs774\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs775\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs776\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs777\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs778\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs779\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs780\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs781\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs782\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs783\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs784\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs785\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs786\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs787\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs788\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs789\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs790\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs791\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs792\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs793\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs794\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs795\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs796\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs797\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs798\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs799\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs800\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs801\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs802\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs803\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs804\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs805\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs806\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs807\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs808\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs809\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs810\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs811\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs812\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs813\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs814\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs815\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs816\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs817\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs818\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs819\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs820\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs821\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs822\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs823\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs824\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs825\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs826\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs827\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs828\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs829\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs830\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs831\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs832\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs833\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs834\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs835\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs836\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs837\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs838\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs839\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs840\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs841\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs842\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs843\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs844\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs845\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs846\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs847\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs848\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs849\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs850\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs851\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs852\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs853\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs854\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs855\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs856\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs857\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs858\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs859\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs860\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs861\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs862\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs863\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs864\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs865\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs866\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs867\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs868\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs869\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs870\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs871\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs872\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs873\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs874\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs875\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs876\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs877\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs878\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs879\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs880\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs881\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs882\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs883\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs884\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs885\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs886\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs887\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs888\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs889\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs890\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs891\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs892\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs893\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs894\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs895\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs896\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs897\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs898\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs899\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs900\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs901\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs902\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs903\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs904\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs905\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs906\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs907\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs908\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs909\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs910\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs911\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs912\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs913\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs914\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs915\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs916\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs917\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs918\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs919\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs920\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs921\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs922\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs923\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs924\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs925\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs926\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs927\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs928\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs929\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs930\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs931\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs932\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs933\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs934\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs935\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs936\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs937\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs938\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs939\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs940\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs941\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs942\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs943\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs944\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs945\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs946\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs947\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs948\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs949\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs950\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs951\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs952\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs953\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs954\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs955\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs956\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs957\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs958\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs959\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs960\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs961\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs962\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs963\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs964\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs965\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs966\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs967\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs968\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs969\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs970\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs971\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs972\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs973\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs974\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs975\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs976\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs977\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs978\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs979\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs980\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs981\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs982\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs983\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs984\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs985\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs986\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs987\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs988\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs989\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs990\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs991\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs992\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs993\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs994\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs995\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n",
      "Epochs996\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.3188353844158131\n",
      "\n",
      "Epochs997\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581294\n",
      "\n",
      "Epochs998\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.318835384415813\n",
      "\n",
      "Epochs999\n",
      "Training cost :207.7766577743083\n",
      "Training MAE :16.441159567375884\n",
      "Weights are :   [29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias is :  0.31883538441581283\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "0.31883538441581283\n"
     ]
    }
   ],
   "source": [
    "#trainig the train part of the module using gradient descent\n",
    "theta = np.zeros(x.shape[1])  #weight array\n",
    "bias = 0 \n",
    "l=0.1 #learning rate(alpha)\n",
    "epochs = 1000  #no of training iterations\n",
    "\n",
    "n=x.shape[0]\n",
    "costs_train=[] \n",
    "m_train = y.shape[0]\n",
    "\n",
    "for i in range(epochs):\n",
    "    y_pred = np.dot(x,theta)+bias #forward prop\n",
    "    cost_train = (1/(2*n))*np.sum(np.square(y_pred-y)) #loss MSE (Cost function)\n",
    "    dz = (1/n)*(y_pred-y) #backpropagation  (dcost_train/dy_pred)\n",
    "    dw = np.dot(dz.T,x)   #backPropagation (dcost_train/dtheta = (dcost_train/dy_pred)*(dy_pred/dtheta)) \n",
    "    db = np.sum(dz)             #backpropagation (dcost_train/dbias)\n",
    "    theta = theta - l*dw\n",
    "    bias = bias - l*db \n",
    "    \n",
    "    #Taking every 10th iteration for plotting the graph\n",
    "    if(i%10==0):\n",
    "        costs_train.append(cost_train)\n",
    "    \n",
    "    #MAE (Mean absolute error) train\n",
    "    MAE= (1/m_train)*np.sum(np.abs(y_pred-y))\n",
    "    \n",
    "    #printing values\n",
    "    print(\"Epochs\"+str(i))\n",
    "    print(\"Training cost :\"+str(cost_train))\n",
    "    print(\"Training MAE :\"+str(MAE))\n",
    "    print(\"Weights are :   \"+str(theta))\n",
    "    print(\"Bias is :  \"+str(bias))\n",
    "    print(\"\")\n",
    "    \n",
    "plt.plot(costs_train)\n",
    "plt.show()\n",
    "print(theta)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.151684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.879768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-25.876262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-47.635840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-102.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-88.148510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-194.762401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>123.081573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>62.994783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>53.281684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target\n",
       "0    112.151684\n",
       "1    115.879768\n",
       "2    -25.876262\n",
       "3    -47.635840\n",
       "4   -102.517982\n",
       "..          ...\n",
       "395  -88.148510\n",
       "396 -194.762401\n",
       "397  123.081573\n",
       "398   62.994783\n",
       "399   53.281684\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "y_pred_test = np.dot(x_test,theta)+bias\n",
    "y_pred_test = pd.DataFrame(y_pred_test,columns = ['Target'])\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing my model with sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LinearRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights :[29.59359198 94.65067706  8.37544469 45.52303635  2.46461552]\n",
      "Bias :0.3188353844158158\n"
     ]
    }
   ],
   "source": [
    "# print the bias and weights\n",
    "print(\"Weights :\"+str(lr.coef_))\n",
    "print(\"Bias :\"+ str(lr.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.151684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.879768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-25.876262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-47.635840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-102.517982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-88.148510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-194.762401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>123.081573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>62.994783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>53.281684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target\n",
       "0    112.151684\n",
       "1    115.879768\n",
       "2    -25.876262\n",
       "3    -47.635840\n",
       "4   -102.517982\n",
       "..          ...\n",
       "395  -88.148510\n",
       "396 -194.762401\n",
       "397  123.081573\n",
       "398   62.994783\n",
       "399   53.281684\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lr.predict(x_test)\n",
    "pred = pd.DataFrame(pred , columns = ['Target'])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
